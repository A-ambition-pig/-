# 核心问题

### Hadoop解决数据倾斜

1、提前在map进行combiner操作，减少传输的数据量

2、导致数据倾斜的key大量分布在不同的mapper

1）局部聚合加全局聚合

思想；两次mr。第一次将key随机散列到不同reducer进行处理达到负载均衡目的。第二次再根据去掉key的随机前缀，按原key进行reduce处理。

2）增加reducer，提升并行度

3）自定义分区

根据数据分布情况，自定义散列函数，将key均匀分配到不同的Reducer。



### Hive优化

1、MapJoin

如果不指定或者不符合条件，Hive解析器会将join操作转换成CommonJoin，即：在Reduce阶段完成join。容易发生数据倾斜。

可以用MapJoin把小表全部加载到内存在map端进行join，避免reducer处理

2、行列过滤

列处理：在select中，只拿需要的列

行处理：在分区裁剪中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤。即：先将副表过滤之后再关联

3、列式存储

4、分区/分桶

5、合理设置Map数

1）通常情况下，作业会通过input的目录产生一个或多个map任务

主要决定因素：input文件总个数、input文件大小、集群设置的文件块大小

2）是不是map数越多越好？

否，如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当成一个块，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理时间，就会造成很大的资源浪费。而且，用时执行的map数是受限的

3）是不是保证每个map处理接近128m的文件块，就高枕无忧了？

不一定，如果一个小于128m的文件，只有一两个字段，却又几千万的记录，如果map处理逻辑比较复杂，用一个map去做，也会比较耗时。

针对2）和 3），需要减少map数和增加map数。

6、小文件合并

在Map执行前合并小文件，减少Map数：CombinerHiveInputFormat具有对小文件进行合并的功能（系统默认）。HiveInputFormat没有对小文件合并功能。

7、合理设置Reduce数

Reduce个数并不是越多越好

1）过多的启动和初始化比较耗费时间和资源

2）有多少个Reduce，就会有多少个输出文件。如果生成了很多个小文件，作为另一个任务的输入就会出现小文件过多的问题

考虑原则：处理大数据量利用合适的Reduce数、使用单个Reduce时数据量大小要合适

8、开启map端combiner（不影响最终业务逻辑）

set hive.map.aggr=true;

9、压缩（选择快的）

设置map端输出、中间结果压缩

10、开启JVM重用

同一个作业的task串行执行，但是会导致资源占用而无法被其他job使用



### Hive解决数据倾斜

1、怎么产生的数据倾斜？

不同数据类型关联产生数据倾斜

比如，用户表中的user_id字段为int，log表中的user_id既有string类型也有int类型。当按照user_id进行join操作时，默认的Hash操作会按int型的id来分配，会导致所有string类型的id记录分配到一个Reducer中

解决方式：把数字类型转换成字符串类型

2、解决数据倾斜的方法

1）group by

解决方式：采用sum() group by的方式来替换count(distinct)完成计算。

但是，只能对类似于主键这种字段进行sql改写

2）mapjoin

3）开启数据倾斜时负载均衡

set hive.groupby.skewindata=true

思想：就是先随机分发处理，再按照key group by来分发处理

即：先局部聚合再全局聚合，生成的查询计划会有两个MRJob

4）控制null值分布

将为null的key转变为字符串加随机数/纯随机数，将因null值造成倾斜的数据分不到多个Reducer。

注意：如果异常值不需要的话，最好提前在where条件里面过滤掉

实际中，可以使用case when对空值赋上随机值。

```sql
select 
userid,
name 
  from user_info a 
    join (select 
          case when userid is null  then  cast (rand(47)* 100000 as int ) 
                                    else userid end 
            from user_read_log) b on a.userid = b.userid

```

如果上述的方法还不能解决，比如当有多个Join的时候，建议建立临时表，然后拆分HQL语句



### Spark的架构与作业提交流程

![](F:\bigdata\BigDataLearning\面试点\yarn cluster.png)

### SparkStreaming消费kafka中的数据

1、基于Receiver的方式

Receiver是使用Kafka的高层次Consumer API实现的。receiver从kafka中获取的数据都是存储在spark Executor的内存中的，然后Spark Streaming启动job会去处理那些数据

在默认配置下，这种方式可能会因为底层的失败而丢失数据。如果要启动高可靠机制，让数据零丢失，就必须启动SparkStreaming的预写日志机制(WriteAheadLog，WAL)。该机制会同步地将接收到的Kafka数据写入分布式文件系统上的预写日志中。

2、基于Direct的方式

在spark1.3引入。替代掉使用Receiver来接受数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定的offset范围的数据。

优点：简化并行读取、高性能

一次且仅一次的事务机制

3、对比

基于receiver的方式，是使用Kafka的高阶API来在Zookeeper中保存消费过的offset的。这是消费Kafka数据的传统方式。能保证数据零丢失，但不能保证数据exactly once消费，因为spark和zookeeper之间是不同步的

基于direct的方式，使用kafka的简单api，spark streaming自己负责追踪消费的offset，并保存在checkpoint中。



### Spark中的数据倾斜

包括SparkStreaming和SparkSql，表现主要有下面几种：

1）Executor lost；OOM，Shuffle过程出错

2）Driver OOM

3）单个Executor执行时间特别久，整体任务卡在某个阶段不能结束

4）正常运行的任务突然失败

1、数据倾斜产生原因

1）key分布不均匀

2）建表时考虑不周

3）业务数据激增

某个字段下某种类型的数据量激增， 导致与其他表关联时就直接数据倾斜

2、解决数据倾斜的思路

重点：对数据设计和业务的理解

可以用和平台无关的方式解决，如更好的数据预处理、异常值的过滤等

1）业务逻辑

数据激增的字段单独来做计算

2）程序层面

优化sql

3）调参方面

4）从业务和数据上解决数据倾斜

很多数据倾斜都是在数据的使用上造成的。

```
1、有损的方法：找到异常数据，比如ip为0的数据，过滤掉
2、无损的方法：对分布不均匀的数据，单独计算
3、先对key做一层hash，将数据随机打散并让他们的并行度变大，再汇集
4、数据预处理
```

